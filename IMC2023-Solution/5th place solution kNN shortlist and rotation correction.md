# 5th place solution: kNN shortlist and rotation correction

## Overview

Basically, the stereo matching part is the same as that of the winning solution in 2022, the crop and multi-scale ensemble composition by DBSCAN. In addition to this, the improvement of the shortlist, the improvement of computational efficiency, and rotation correction are the main features of my solution.

Both stage1 and stage2 use SPSG (SuperPoint & SuperGLUE) and MatchFormer. For large scenes, the MatchFormer in stage2 is skipped.

## kNN shortlist + completion

In the baseline, the euclidean distance of the global descriptor is used to filter stereo matching candidates by a threshold value. However, since the scale of the distance differs among datasets, I thought it would not be appropriate to use a common threshold value. It‚Äôs not robust to unknown data sets.

Since the number of images per scene is only about 200 at most, stereo matching and RANSAC verification can be performed **using a very lightweight model** for all image combinations. The shortlist was generated by extracting the k nearest neighbors for each image based on the number of inliers.

The very lightweight model may not match well enough. Some scenes produce images that do not match any of the images. This is fatal because it prevents camera pose estimation. Therefore, image pairs were complementarily added to the shortlist so that there are at least k neighbors for all images by the number of matching keypoints.

**The very lightweight model**: I used SPSG as the very lightweight model. The number of keypoints was set to 512 for efficiency as shown in Fig. 11, Appendix B of superglue's paper.

## Rotation correction

A notable weakness of superglue's pretrained model is its lack of robustness to rotation. This is especially noticeable in the heritage dataset of the IMC2023 training set, cyprus scene. I addressed this issue without training by just rotating images.

![img](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F6388%2F212bfdaf476e1ec79efa5692162d99d2%2Fcyprus1.png?generation=1686630454984938&alt=media)

![img](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F6388%2F75ce985499c56086b721df6a3e63e5d1%2Fcyprus2.png?generation=1686630470817962&alt=media)

Specifically, 4 different rotated images were prepared and matched using the very lightweight model. All images were resized to the same size (840x840) and processed in one batch.

## Parallel Execution

GPU-intensive and CPU-intensive tasks can be executed in parallel for efficiency. Specifically, COLMAP BA is a CPU-intensive task, but stereo matching is a GPU-intensive task. Therefore, I implemented COLMAP processing in a separate thread and run it in parallel with stereo matching.

## Local Validation

Only some difficult scenes were verified in the local environment. In particular, dioscuri, which has 174 images, was used as a reference to adjust the algorithm so that it would not time out.

| scene               | # images | score  | time (local env) |
| ------------------- | -------- | ------ | ---------------- |
| bike                | 15       | 0.9342 | 134 s            |
| kyiv-puppet-theater | 27       | 0.7781 | 291 s            |
| cyprus              | 30       | 0.6239 | 312 s            |
| wall                | 43       | 0.4753 | 851 s            |
| dioscuri            | 174      | 0.8775 | 2045 s           |

## Processing time

My best submisison run time was **7 hours and 40 minutes**. This is well under the time limit of 9 hours. Therefore, I added LoFTR to ensemble on the last day, but the Kaggle server is broken and the notebook is still running. If the notebook had been successfully processed, My best submission could have been a little better.

![img](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F6388%2F538925ab8b7ece79f2630f2a9f18708e%2Ferrors.png?generation=1686630579463016&alt=media)

The issue of not being able to submit on the last day is very stressful. Something similar occurred with Google Landmark Recognition in 2019. I pray that this kind of trouble will not occur againüôè

## Things doesn‚Äôt woks

- TTA ‚Ä¶ no significant improvement
- Pixel-Perfect SfM .. I got a slight improvement in my local environment but gave up because I couldn't set up ceres in my kaggle notebook
- TensorRT .. I had to downgrade from PyTorch 2.0, but the setup was successful. I can't say with much certainty, but at least my experiments did not improve execution speed.
- Half precision ‚Ä¶ It was about 10%(?) faster, but mAA was worse, so it was not adopted in the end.
- other matchers ‚Ä¶ Tried DKMv3, LoFTR, Silk, but finally used only SPSG and MatchFormer due to high mAA.
- Incremental Mapper parameter tuning ‚Ä¶ contributed to the stable high score in the local environment. Specifically, I reduced the max refinement change of BA and increased the max num iteration. However, all the submissions to kaggle were out of memory, so I did not check the improvement on the leaderboard.